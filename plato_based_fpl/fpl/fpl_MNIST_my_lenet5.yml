clients:
    # Type
    type: simple

    # The total number of clients
    total_clients: 49

    # The number of clients selected in each round
    per_round: 5

    # Should the clients compute test accuracy locally?
    do_test: false

    training_time: 13, 18, 4, 4, 19, 11, 2, 6, 19, 3, 8, 3, 5, 5, 10, 14, 14, 13, 6, 2, 14, 20, 16, 20, 15, 5, 15, 19, 17, 9, 13, 12, 20, 18, 15, 11, 11, 9, 10, 10, 7, 16, 14, 3, 12, 6, 14, 16, 5

server:
    address: 127.0.0.1
    port: 8000
    cut_off: 0.7

data:
    # The training and testing dataset
    # datasource: CIFAR10
    datasource: MNIST
    # data_path: ../datasetsAndModels/MNIST_group
    data_path: ../datasetsAndModels/MNIST_group

    aigc_datasource: aigc_MNIST
    # aigc_data_path: ../datasetsAndModels/5
    aigc_data_path: ../datasetsAndModels/aigc_MNIST

    aug_datasource: aug_MNIST
    aug_data_path: ../datasetsAndModels/MNIST_group


    # Number of samples in each partition
    partition_size: 300      # 300
    partition_size_aigc: 450

    # The expected distribution of preference classes
    server_PC: 0,1
    server_exp: 0.3

    # the aigc speed in each round
    aigc_speed: 500
    # fpl sampler
    sampler: fpl_distribution
    # sampler: iid
    concentrate: 0.6
    # sampler: iid
    # fpl_expectation: 0.4,0.4,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025
    # fpl_expectation: 0.3,0.3,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05
    fpl_expectation: 0.2,0.2,0.075,0.075,0.075,0.075,0.075,0.075,0.075,0.075
    # fpl_expectation: 0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1

    fpl_expectation_test: 0.5,0.5,0,0,0,0,0,0,0,0

    # sampler: label_quantity_noniid
    # per_client_classes_size: 3

    # The random seed for sampling data
    random_seed: 1

trainer:
    # The type of the trainer
    type: basic

    # The maximum number of training rounds
    rounds: 100

    # The maximum number of clients running concurrently
    max_concurrency: 5

    # The target accuracy
    target_accuracy: 1

    # The machine learning model
    model_name: lenet5

    # Number of epoches for local training in each communication round
    epochs: 1
    batch_size: 32
    optimizer: SGD

algorithm:
    # Aggregation algorithm
    type: fedavg
    # total_silos: 10

parameters:
    optimizer:
        lr: 0.01
        momentum: 0.9
        weight_decay: 0.0
        
results:
    result_path: ./FPL_MNIST_pc01

    # Write the following parameter(s) into a CSV
    types: round, accuracy, elapsed_time, round_time